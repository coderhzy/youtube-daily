"""
AI Processor for news content using OpenRouter
"""

from typing import List, Dict, Any
from openai import OpenAI

from src.config import (
    OPENROUTER_API_KEY,
    OPENROUTER_BASE_URL,
    OPENROUTER_MODEL,
    ENABLE_AI_SUMMARY
)
from src.utils.logger import get_logger

class AIProcessor:
    """AI processor using OpenRouter for content generation"""

    def __init__(self):
        self.logger = get_logger('ai_processor')

        if not OPENROUTER_API_KEY:
            raise ValueError("OPENROUTER_API_KEY must be set in environment variables")

        self.client = OpenAI(
            api_key=OPENROUTER_API_KEY,
            base_url=OPENROUTER_BASE_URL
        )
        self.model = OPENROUTER_MODEL
        self.logger.info(f"AI Processor initialized with model: {self.model}")

    def process_daily_news(
        self,
        news_list: List[Dict[str, Any]],
        date_str: str
    ) -> Dict[str, Any]:
        """
        Process daily news and generate blog article

        Args:
            news_list: List of news items
            date_str: Date string (YYYY-MM-DD)

        Returns:
            Dict containing title, content, description, tags, attractive_title, cover_prompt
        """
        if not ENABLE_AI_SUMMARY:
            self.logger.info("AI summary is disabled, using basic formatting")
            return self._basic_format(news_list, date_str)

        try:
            self.logger.info(f"Processing {len(news_list)} news items with AI...")

            # Prepare news text
            news_text = self._prepare_news_text(news_list)

            # Call AI to generate article
            prompt = self._create_prompt(news_text, date_str)

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„åŒºå—é“¾è¡Œä¸šåˆ†æå¸ˆå’Œæ·±åº¦å†…å®¹åˆ›ä½œè€…,æ“…é•¿æ’°å†™è¯¦å®ã€æœ‰æ´å¯ŸåŠ›çš„è¡Œä¸šè§‚å¯Ÿæ–‡ç« ã€‚ä½ çš„æ–‡ç« ä¿¡æ¯é‡å¤§ã€åˆ†ææ·±å…¥,æ·±å—ä¸“ä¸šè¯»è€…å–œçˆ±ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=16000  # æ”¯æŒæ›´é•¿çš„è¾“å‡ºï¼ˆçº¦10kä¸­æ–‡å­—ï¼‰
            )

            result = response.choices[0].message.content

            # Parse AI response
            parsed_result = self._parse_ai_response(result, date_str)

            # Generate attractive title and cover image prompt
            self.logger.info("Generating attractive title and cover image prompt...")
            title_and_cover = self._generate_attractive_title_and_cover(news_text, parsed_result['content'])

            parsed_result['attractive_title'] = title_and_cover['title']
            parsed_result['cover_prompt'] = title_and_cover['cover_prompt']

            self.logger.info("AI processing completed successfully")
            return parsed_result

        except Exception as e:
            self.logger.error(f"Error in AI processing: {e}")
            self.logger.info("Falling back to basic formatting")
            return self._basic_format(news_list, date_str)

    def _prepare_news_text(self, news_list: List[Dict[str, Any]]) -> str:
        """Prepare news text for AI processing"""
        news_items = []
        for i, news in enumerate(news_list, 1):
            source = news.get('source', 'æœªçŸ¥æ¥æº')
            title = news.get('title', '')
            content = news.get('content', '')

            news_items.append(
                f"{i}. [{source}] {title}\n   {content}"
            )

        return "\n\n".join(news_items)

    def _create_prompt(self, news_text: str, date_str: str) -> str:
        """Create AI prompt"""
        return f"""è¯·å°†ä»¥ä¸‹åŒºå—é“¾æ–°é—»æ•´ç†æˆä¸€ç¯‡**æ·±åº¦ã€è¯¦ç»†**çš„æ¯æ—¥è§‚å¯Ÿåšå®¢æ–‡ç« ã€‚

æ—¥æœŸ: {date_str}

æ–°é—»å†…å®¹:
{news_text}

è¯·æŒ‰ä»¥ä¸‹è¦æ±‚å¤„ç†:

1. **æ–‡ç« é•¿åº¦**: ç›®æ ‡8000-10000å­—ï¼ˆæ·±åº¦åˆ†æç‰ˆæœ¬ï¼‰

2. **æ–‡ç« ç»“æ„**:

   a) **å¼€ç¯‡æ€»ç»“** (500-800å­—):
      - å…¨é¢æ€»ç»“ä»Šæ—¥æœ€é‡è¦çš„åŠ¨æ€
      - æç‚¼æ ¸å¿ƒä¸»é¢˜å’Œå®è§‚è¶‹åŠ¿
      - å»ºç«‹å„ä¸ªæ¿å—ä¹‹é—´çš„è”ç³»
      - åˆ†æèƒŒåçš„æ·±å±‚åŸå› 

   b) **åˆ†ç±»æ·±åº¦åˆ†æ**: å°†æ–°é—»åˆ†ä¸º5-7ä¸ªä¸»è¦æ¿å—ï¼Œæ¯ä¸ªæ¿å—è¿›è¡Œæ·±åº¦å‰–æ:
      - ğŸ“Š **å¸‚åœºåŠ¨æ€** (ä»·æ ¼èµ°åŠ¿ã€äº¤æ˜“é‡åˆ†æã€å¸‚åœºæƒ…ç»ªã€æŠ€æœ¯åˆ†æã€é“¾ä¸Šæ•°æ®)
      - ğŸ›ï¸ **æ”¿ç­–ç›‘ç®¡** (å„å›½ç›‘ç®¡åŠ¨å‘ã€åˆè§„è¦æ±‚ã€æ”¿ç­–å½±å“ã€è¡Œä¸šåº”å¯¹)
      - ğŸ’° **DeFiç”Ÿæ€** (åè®®æ›´æ–°ã€TVLå˜åŒ–ã€æ”¶ç›Šæœºä¼šã€é£é™©åˆ†æã€åˆ›æ–°æ¨¡å¼)
      - ğŸ¨ **NFTä¸é“¾æ¸¸** (æ–°é¡¹ç›®ã€äº¤æ˜“æ•°æ®ã€å¸‚åœºçƒ­ç‚¹ã€ç”¨æˆ·å¢é•¿ã€ç”Ÿæ€å‘å±•)
      - ğŸ”§ **æŠ€æœ¯åˆ›æ–°** (åè®®å‡çº§ã€Layer2è¿›å±•ã€æ–°æŠ€æœ¯è½åœ°ã€æ€§èƒ½ä¼˜åŒ–ã€å®‰å…¨æ”¹è¿›)
      - ğŸ’¼ **æŠ•èèµ„** (èèµ„äº‹ä»¶ã€æŠ•èµ„æœºæ„åŠ¨å‘ã€ä¼°å€¼åˆ†æã€èµ›é“è¶‹åŠ¿)
      - ğŸŒ **è¡Œä¸šåŠ¨æ€** (æœºæ„å…¥åœºã€ç”Ÿæ€å‘å±•ã€è¡Œä¸šåˆä½œã€æˆ˜ç•¥å¸ƒå±€)

   c) **æ·±åº¦æ€»ç»“ä¸å±•æœ›** (500-800å­—):
      - ä»Šæ—¥æ–°é—»çš„æ ¸å¿ƒè¦ç‚¹æ¢³ç†
      - è·¨æ¿å—çš„è”åŠ¨åˆ†æ
      - çŸ­æœŸè¶‹åŠ¿é¢„æµ‹
      - ä¸­é•¿æœŸå½±å“è¯„ä¼°
      - æŠ•èµ„è€…å»ºè®®ï¼ˆé£é™©æç¤ºï¼‰

3. **å†…å®¹æ·±åº¦è¦æ±‚**:
   - **æ¯æ¡é‡è¦æ–°é—»**: ç”¨150-300å­—æ·±åº¦è§£è¯»
   - **æ¯æ¡æ¬¡è¦æ–°é—»**: ç”¨80-150å­—æ¦‚æ‹¬åˆ†æ

   - **å¿…é¡»æ·»åŠ ä¸“ä¸šæ´å¯Ÿ**:
     * å¼•ç”¨å…·ä½“çš„è¡Œä¸šæ•°æ®å’ŒæŒ‡æ ‡ï¼ˆTVLã€äº¤æ˜“é‡ã€å¸‚å€¼ç­‰ï¼‰
     * å¯¹æ¯”å†å²ç±»ä¼¼äº‹ä»¶åŠå…¶åç»­å½±å“
     * æ·±å…¥åˆ†æå› æœå…³ç³»å’Œä¼ å¯¼æœºåˆ¶
     * åŸºäºæ•°æ®é¢„æµ‹æœªæ¥èµ°å‘
     * è¯„ä¼°å¯¹ä¸åŒå‚ä¸è€…çš„å½±å“ï¼ˆæ•£æˆ·ã€æœºæ„ã€é¡¹ç›®æ–¹ï¼‰

4. **è¯­è¨€é£æ ¼**:
   - ä¸“ä¸šä½†æ˜“æ‡‚ï¼Œé¢å‘å¯¹åŒºå—é“¾æœ‰ä¸€å®šäº†è§£çš„è¯»è€…
   - ä½¿ç”¨æ•°æ®æ”¯æ’‘è§‚ç‚¹
   - ä¿æŒå®¢è§‚ä¸­ç«‹ï¼Œä½†å¯ä»¥æä¾›ç‹¬åˆ°è§è§£
   - é€‚å½“ä½¿ç”¨è¡Œä¸šæœ¯è¯­ï¼Œå¹¶ç®€è¦è§£é‡Š

5. **æ ¼å¼è¦æ±‚**:
   - ä½¿ç”¨Markdownæ ¼å¼
   - æ¯ä¸ªæ¿å—ç”¨äºŒçº§æ ‡é¢˜(##)
   - é‡è¦æ–°é—»ç”¨ä¸‰çº§æ ‡é¢˜(###)
   - æ¬¡è¦æ–°é—»ç”¨åˆ—è¡¨é¡¹(-)
   - å…³é”®æ•°æ®ç”¨**ç²—ä½“**æ ‡æ³¨
   - é€‚å½“ä½¿ç”¨å¼•ç”¨å—(>)çªå‡ºé‡è¦è§‚ç‚¹

è¯·ç›´æ¥è¾“å‡ºMarkdownæ ¼å¼çš„æ–‡ç« å†…å®¹ï¼Œç¡®ä¿å†…å®¹å……å®ã€åˆ†ææ·±å…¥ã€ä¿¡æ¯é‡å¤§ã€‚"""

    def _parse_ai_response(self, ai_response: str, date_str: str) -> Dict[str, Any]:
        """Parse AI response"""
        lines = ai_response.strip().split('\n')
        description_lines = []
        content_start = 0

        # è¿‡æ»¤æ‰AIçš„ç¤¼è²Œæ€§å›å¤å¼€å¤´
        skip_phrases = [
            'å¥½çš„', 'è¿™æ˜¯', 'æ ¹æ®', 'æ‚¨æä¾›', 'æ•´ç†è€Œæˆ',
            'ä»¥ä¸‹æ˜¯', 'ä¸ºæ‚¨', 'æˆ‘å°†', 'è®©æˆ‘', '---', '**æ—¥æœŸï¼š'
        ]

        for i, line in enumerate(lines):
            if line.startswith('##'):
                content_start = i
                break

            # è·³è¿‡ç©ºè¡Œå’Œä»¥#å¼€å¤´çš„è¡Œ
            if not line.strip() or line.startswith('#'):
                continue

            # è·³è¿‡åŒ…å«ç¤¼è²Œæ€§å›å¤çš„è¡Œ
            if any(phrase in line for phrase in skip_phrases):
                continue

            # åªæ·»åŠ æœ‰å®é™…å†…å®¹çš„è¡Œ
            if line.strip():
                description_lines.append(line.strip())

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„æè¿°ï¼Œä½¿ç”¨é»˜è®¤æè¿°
        if description_lines:
            description = ' '.join(description_lines[:2])  # åªå–å‰2è¡Œï¼Œé¿å…å¤ªé•¿
        else:
            description = f"åŒºå—é“¾æ¯æ—¥è§‚å¯Ÿ - {date_str}"

        content = '\n'.join(lines[content_start:]) if content_start > 0 else ai_response

        tags = self._extract_tags(content)

        return {
            'title': f"åŒºå—é“¾æ¯æ—¥è§‚å¯Ÿ - {date_str}",
            'content': content,
            'description': description[:200],  # é™åˆ¶200å­—ç¬¦
            'tags': tags
        }

    def _extract_tags(self, content: str) -> List[str]:
        """Extract tags from content"""
        tags = ['åŒºå—é“¾', 'æ¯æ—¥è§‚å¯Ÿ']

        content_lower = content.lower()

        if 'defi' in content_lower or 'å»ä¸­å¿ƒåŒ–é‡‘è' in content:
            tags.append('DeFi')
        if 'nft' in content_lower or 'æ•°å­—è—å“' in content:
            tags.append('NFT')
        if 'æ¯”ç‰¹å¸' in content or 'bitcoin' in content_lower or 'btc' in content_lower:
            tags.append('æ¯”ç‰¹å¸')
        if 'ä»¥å¤ªåŠ' in content or 'ethereum' in content_lower or 'eth' in content_lower:
            tags.append('ä»¥å¤ªåŠ')
        if 'ç›‘ç®¡' in content or 'æ”¿ç­–' in content:
            tags.append('æ”¿ç­–ç›‘ç®¡')
        if 'èèµ„' in content or 'æŠ•èµ„' in content:
            tags.append('æŠ•èèµ„')

        return list(set(tags))

    def _generate_attractive_title_and_cover(self, news_text: str, article_content: str) -> Dict[str, str]:
        """
        Generate attractive title and cover image prompt based on article content

        Args:
            news_text: Raw news text
            article_content: Processed article content

        Returns:
            Dict with 'title' and 'cover_prompt'
        """
        try:
            prompt = f"""åŸºäºä»¥ä¸‹åŒºå—é“¾æ–°é—»æ–‡ç« ï¼Œç”Ÿæˆä¸€ä¸ªå¸å¼•äººçš„YouTubeè§†é¢‘æ ‡é¢˜å’Œå°é¢å›¾æè¿°ã€‚

æ–‡ç« æ‘˜è¦:
{article_content[:1000]}...

è¦æ±‚:

1. **YouTubeè§†é¢‘æ ‡é¢˜**ï¼ˆ10-25ä¸ªå­—ï¼‰:
   - æŠ“ä½ä»Šæ—¥æœ€æ ¸å¿ƒã€æœ€å¸å¼•çœ¼çƒçš„è¯é¢˜
   - ä½¿ç”¨æ•°å­—ã€æƒ…æ„Ÿè¯ã€æ‚¬å¿µç­‰æŠ€å·§
   - é€‚åˆYouTubeç®—æ³•æ¨è
   - ç¤ºä¾‹: "æ¯”ç‰¹å¸æš´è·Œ20%ï¼å·¨é²¸å´åœ¨ç–¯ç‹‚æŠ„åº•ï¼Ÿ"
   - ç¤ºä¾‹: "ä»¥å¤ªåŠé‡å¤§å‡çº§ï¼Gasè´¹ç”¨é™ä½90%"
   - ç¤ºä¾‹: "ç¾å›½SECçªå‘æ–°æ”¿ï¼åŠ å¯†å¸‚åœºå°†è¿æ¥å·¨å˜ï¼Ÿ"

2. **å°é¢å›¾æç¤ºè¯**ï¼ˆè‹±æ–‡ï¼Œç”¨äºNano Banana Proå›¾ç‰‡ç”Ÿæˆï¼‰:
   - å¿…é¡»åŒ…å«å¸å¼•äººçš„äººç‰©åœºæ™¯
   - çªå‡ºä»Šæ—¥æœ€é‡è¦çš„ä¸»é¢˜
   - é€‚åˆYouTubeç¼©ç•¥å›¾ï¼ˆ16:9æ¨ªå±ï¼‰
   - åŒ…å«æ¸…æ™°çš„ä¸­æ–‡æ ‡é¢˜æ–‡å­—
   - è§†è§‰å†²å‡»åŠ›å¼ºï¼Œè®©äººæƒ³ç‚¹å‡»
   - ç¬¦åˆNano Banana Proçš„æ–‡å­—æ¸²æŸ“ä¼˜åŠ¿

è¯·ä»¥JSONæ ¼å¼è¿”å›:
{{
  "title": "å¸å¼•äººçš„YouTubeæ ‡é¢˜",
  "cover_prompt": "Detailed English prompt for cover image generation"
}}

å°é¢å›¾æç¤ºè¯ç¤ºä¾‹æ ¼å¼:
"Create a dramatic YouTube thumbnail image for blockchain news.
Scene: Shocked/excited business analyst looking at large digital screen showing [KEY EVENT],
dramatic lighting, urgent atmosphere, close-up professional photography style.
Chinese title text: '[YouTubeæ ‡é¢˜]' in large bold white characters (90pt+) at top,
highly visible and readable using Nano Banana Pro's superior text rendering.
Visual elements: Bitcoin/crypto symbols, price charts with dramatic arrows,
breaking news aesthetic, red/green color accents for market emotions.
Background: Gradient dark blue to black, cinematic lighting, high contrast.
Style: YouTube thumbnail optimized, attention-grabbing, professional yet dramatic,
perfect for video presentation, 16:9 horizontal format.
Text rendering: Ensure Chinese characters are crystal clear and prominent using
Nano Banana Pro's industry-leading multilingual text capabilities."

æ³¨æ„: æ ‡é¢˜è¦èƒ½å¼•èµ·å¥½å¥‡å¿ƒå’Œç‚¹å‡»æ¬²æœ›ï¼Œå°é¢å›¾è¦è§†è§‰å†²å‡»åŠ›å¼ºï¼"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.8,  # ç¨é«˜çš„æ¸©åº¦ä»¥è·å¾—æ›´æœ‰åˆ›æ„çš„æ ‡é¢˜
                max_tokens=2000
            )

            result = response.choices[0].message.content

            # Parse JSON response
            import json
            import re

            # Extract JSON from markdown code blocks if present
            json_match = re.search(r'```json\s*(.*?)\s*```', result, re.DOTALL)
            if json_match:
                result = json_match.group(1)

            parsed = json.loads(result)

            self.logger.info(f"Generated attractive title: {parsed['title']}")
            return parsed

        except Exception as e:
            self.logger.error(f"Error generating attractive title and cover: {e}")
            # Fallback
            return {
                'title': 'ä»Šæ—¥åŒºå—é“¾è¡Œä¸šé‡å¤§åŠ¨æ€',
                'cover_prompt': 'Professional blockchain news presenter looking at dramatic market charts, urgent atmosphere, Chinese title text visible'
            }

    def _basic_format(self, news_list: List[Dict[str, Any]], date_str: str) -> Dict[str, Any]:
        """Basic formatting without AI"""
        content_parts = [
            f"# åŒºå—é“¾æ¯æ—¥è§‚å¯Ÿ - {date_str}\n",
            f"ä»Šæ—¥å…±æ”¶å½• {len(news_list)} æ¡åŒºå—é“¾è¡Œä¸šåŠ¨æ€\n",
            "---\n"
        ]

        # Group by source
        sources = {}
        for news in news_list:
            source = news.get('source', 'å…¶ä»–')
            if source not in sources:
                sources[source] = []
            sources[source].append(news)

        for source, source_news in sources.items():
            content_parts.append(f"\n## ğŸ“° {source}\n")
            for news in source_news:
                content_parts.append(f"- **{news['title']}**  \n  {news['content']}\n")

        content = '\n'.join(content_parts)

        return {
            'title': f"åŒºå—é“¾æ¯æ—¥è§‚å¯Ÿ - {date_str}",
            'content': content,
            'description': f"åŒºå—é“¾æ¯æ—¥è§‚å¯Ÿ - {date_str},æ”¶å½•{len(news_list)}æ¡è¡Œä¸šåŠ¨æ€",
            'tags': ['åŒºå—é“¾', 'æ¯æ—¥è§‚å¯Ÿ'],
            'attractive_title': f'ä»Šæ—¥åŒºå—é“¾è¡Œä¸šåŠ¨æ€ - {date_str}',
            'cover_prompt': 'Professional blockchain news, modern office setting'
        }
