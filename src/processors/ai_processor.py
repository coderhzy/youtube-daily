"""
AI Processor for news content using OpenRouter
"""

from typing import List, Dict, Any
from openai import OpenAI

from src.config import (
    OPENROUTER_API_KEY,
    OPENROUTER_BASE_URL,
    OPENROUTER_MODEL,
    ENABLE_AI_SUMMARY
)
from src.utils.logger import get_logger

class AIProcessor:
    """AI processor using OpenRouter for content generation"""

    def __init__(self):
        self.logger = get_logger('ai_processor')

        if not OPENROUTER_API_KEY:
            raise ValueError("OPENROUTER_API_KEY must be set in environment variables")

        self.client = OpenAI(
            api_key=OPENROUTER_API_KEY,
            base_url=OPENROUTER_BASE_URL
        )
        self.model = OPENROUTER_MODEL
        self.logger.info(f"AI Processor initialized with model: {self.model}")

    def process_daily_news(
        self,
        news_list: List[Dict[str, Any]],
        date_str: str
    ) -> Dict[str, Any]:
        """
        Process daily news and generate blog article

        Args:
            news_list: List of news items
            date_str: Date string (YYYY-MM-DD)

        Returns:
            Dict containing title, content, description, tags, attractive_title, cover_prompt
        """
        if not ENABLE_AI_SUMMARY:
            self.logger.info("AI summary is disabled, using basic formatting")
            return self._basic_format(news_list, date_str)

        try:
            self.logger.info(f"Processing {len(news_list)} news items with AI...")

            # Prepare news text
            news_text = self._prepare_news_text(news_list)

            # Call AI to generate article
            prompt = self._create_prompt(news_text, date_str)

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä½åŒºå—é“¾YouTubeåšä¸»ï¼Œæ“…é•¿ç”¨å£è¯­åŒ–ã€æ¥åœ°æ°”çš„æ–¹å¼è®²è§£è¡Œä¸šæ–°é—»ã€‚ä½ çš„é£æ ¼æ˜¯ï¼šç®€æ´ç›´æ¥ã€ä¸ç”¨ä¹¦é¢è¯­ã€åƒå’Œæœ‹å‹èŠå¤©ã€‚é¿å…ä½¿ç”¨'å€¼å¾—æ³¨æ„'ã€'æ€»è€Œè¨€ä¹‹'ã€'ä¸å¯å¦è®¤'ç­‰AIè…”è°ƒè¯æ±‡ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.8,
                max_tokens=8000  # æ§åˆ¶è¾“å‡ºé•¿åº¦ï¼ˆçº¦4k-5kä¸­æ–‡å­—ï¼‰
            )

            result = response.choices[0].message.content

            # Parse AI response
            parsed_result = self._parse_ai_response(result, date_str)

            # Generate attractive title and cover image prompt
            self.logger.info("Generating attractive title and cover image prompt...")
            title_and_cover = self._generate_attractive_title_and_cover(news_text, parsed_result['content'])

            parsed_result['attractive_title'] = title_and_cover['title']
            parsed_result['cover_prompt'] = title_and_cover['cover_prompt']

            self.logger.info("AI processing completed successfully")
            return parsed_result

        except Exception as e:
            self.logger.error(f"Error in AI processing: {e}")
            self.logger.info("Falling back to basic formatting")
            return self._basic_format(news_list, date_str)

    def _prepare_news_text(self, news_list: List[Dict[str, Any]]) -> str:
        """Prepare news text for AI processing"""
        news_items = []
        for i, news in enumerate(news_list, 1):
            source = news.get('source', 'æœªçŸ¥æ¥æº')
            title = news.get('title', '')
            content = news.get('content', '')

            news_items.append(
                f"{i}. [{source}] {title}\n   {content}"
            )

        return "\n\n".join(news_items)

    def _create_prompt(self, news_text: str, date_str: str) -> str:
        """Create AI prompt"""
        return f"""è¯·å°†ä»¥ä¸‹åŒºå—é“¾æ–°é—»æ•´ç†æˆä¸€ç¯‡é€‚åˆYouTubeè§†é¢‘è®²è§£çš„è„šæœ¬ã€‚

æ—¥æœŸ: {date_str}

æ–°é—»å†…å®¹:
{news_text}

è¯·æŒ‰ä»¥ä¸‹è¦æ±‚å¤„ç†:

1. **æ–‡ç« é•¿åº¦**: ç›®æ ‡3750-5000å­—ï¼ˆå¯¹åº”15-20åˆ†é’Ÿè§†é¢‘ï¼Œæ¯åˆ†é’Ÿ250å­—ï¼‰

2. **è¯­è¨€é£æ ¼** (éå¸¸é‡è¦ï¼):
   - **å£è¯­åŒ–è¡¨è¾¾**: åƒæœ‹å‹èŠå¤©ä¸€æ ·ï¼Œä¸è¦å†™è®ºæ–‡
   - **å»AIåŒ–**: ç¦æ­¢ä½¿ç”¨"å€¼å¾—æ³¨æ„çš„æ˜¯"ã€"æ€»è€Œè¨€ä¹‹"ã€"ä¸å¯å¦è®¤"ã€"æ¯‹åº¸ç½®ç–‘"ç­‰ä¹¦é¢è¯­æ°”è¯
   - **ç®€æ´ç›´æ¥**: ç”¨çŸ­å¥ï¼Œä¸ç»•å¼¯å­
   - **äº²è¿‘è§‚ä¼—**: å¯ä»¥ç”¨"å’±ä»¬"ã€"å¤§å®¶"ã€"ä½ "ç­‰è¯æ‹‰è¿‘è·ç¦»

   âŒ é”™è¯¯ç¤ºä¾‹: "å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ¯”ç‰¹å¸ä»·æ ¼åœ¨æœ¬å‘¨å‘ˆç°å‡ºäº†è¾ƒä¸ºæ˜æ˜¾çš„ä¸Šæ¶¨è¶‹åŠ¿ï¼Œè¿™æ— ç–‘ä¸ºå¸‚åœºå‚ä¸è€…å¸¦æ¥äº†ç§¯æçš„ä¿¡å·ã€‚"
   âœ… æ­£ç¡®ç¤ºä¾‹: "æ¯”ç‰¹å¸è¿™å‘¨æ¶¨äº†ä¸å°‘ï¼Œå¸‚åœºæƒ…ç»ªæ˜æ˜¾å¥½è½¬ã€‚"

3. **æ–‡ç« ç»“æ„**:

   a) **å¼€åœº** (300-400å­—):
      - ç›´æ¥è¯´ä»Šå¤©æœ€é‡è¦çš„äº‹
      - 2-3ä¸ªæ ¸å¿ƒè¦ç‚¹
      - å¼€é—¨è§å±±ï¼Œä¸é“ºå«

   b) **åˆ†ç±»è®²è§£**: æ ¹æ®æ–°é—»å†…å®¹åˆ†3-5ä¸ªæ¿å—:
      - ğŸ“Š **å¸‚åœºè¡Œæƒ…** (ä»·æ ¼ã€äº¤æ˜“é‡ã€å¸‚åœºæƒ…ç»ª)
      - ğŸ›ï¸ **æ”¿ç­–åŠ¨æ€** (ç›‘ç®¡æ–°é—»ã€æ”¿ç­–å½±å“)
      - ğŸ’° **DeFi/NFT** (åè®®åŠ¨æ€ã€çƒ­ç‚¹é¡¹ç›®)
      - ğŸ”§ **æŠ€æœ¯è¿›å±•** (å‡çº§ã€æ–°æŠ€æœ¯)
      - ğŸ’¼ **èèµ„/æœºæ„** (æŠ•èèµ„ã€æœºæ„åŠ¨å‘)

   c) **æ€»ç»“** (300-400å­—):
      - ç®€å•æ¢³ç†ä»Šå¤©é‡ç‚¹
      - è¯´è¯´åç»­å¯èƒ½çš„å½±å“
      - ç»™è§‚ä¼—ä¸€äº›å®ç”¨å»ºè®®

4. **å†…å®¹æ·±åº¦**:
   - **é‡è¦æ–°é—»**: 100-150å­—è®²æ¸…æ¥š
   - **æ¬¡è¦æ–°é—»**: 50-80å­—æ¦‚æ‹¬
   - **åŠ å…¥è§‚ç‚¹**: ç”¨æ•°æ®è¯´è¯ï¼Œä½†è¦é€šä¿—æ˜“æ‡‚
   - **ä¸¾ä¾‹è¯´æ˜**: å¤æ‚æ¦‚å¿µç”¨ç®€å•ä¾‹å­è§£é‡Š

5. **æ ¼å¼è¦æ±‚**:
   - ä½¿ç”¨Markdownæ ¼å¼
   - æ¿å—ç”¨äºŒçº§æ ‡é¢˜(##)
   - é‡è¦æ–°é—»ç”¨ä¸‰çº§æ ‡é¢˜(###)
   - å…³é”®æ•°å­—ç”¨**ç²—ä½“**
   - ä¸è¦ç”¨å¼•ç”¨å—ï¼Œç›´æ¥è¯´

è¯·ç›´æ¥è¾“å‡ºMarkdownæ ¼å¼çš„è„šæœ¬å†…å®¹ï¼Œè®°ä½ï¼šåƒå’Œæœ‹å‹èŠå¤©ï¼Œä¸è¦å†™è®ºæ–‡ï¼"""

    def _parse_ai_response(self, ai_response: str, date_str: str) -> Dict[str, Any]:
        """Parse AI response"""
        lines = ai_response.strip().split('\n')
        description_lines = []
        content_start = 0

        # è¿‡æ»¤æ‰AIçš„ç¤¼è²Œæ€§å›å¤å¼€å¤´
        skip_phrases = [
            'å¥½çš„', 'è¿™æ˜¯', 'æ ¹æ®', 'æ‚¨æä¾›', 'æ•´ç†è€Œæˆ',
            'ä»¥ä¸‹æ˜¯', 'ä¸ºæ‚¨', 'æˆ‘å°†', 'è®©æˆ‘', '---', '**æ—¥æœŸï¼š'
        ]

        for i, line in enumerate(lines):
            if line.startswith('##'):
                content_start = i
                break

            # è·³è¿‡ç©ºè¡Œå’Œä»¥#å¼€å¤´çš„è¡Œ
            if not line.strip() or line.startswith('#'):
                continue

            # è·³è¿‡åŒ…å«ç¤¼è²Œæ€§å›å¤çš„è¡Œ
            if any(phrase in line for phrase in skip_phrases):
                continue

            # åªæ·»åŠ æœ‰å®é™…å†…å®¹çš„è¡Œ
            if line.strip():
                description_lines.append(line.strip())

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„æè¿°ï¼Œä½¿ç”¨é»˜è®¤æè¿°
        if description_lines:
            description = ' '.join(description_lines[:2])  # åªå–å‰2è¡Œï¼Œé¿å…å¤ªé•¿
        else:
            description = f"åŒºå—é“¾æ¯æ—¥è§‚å¯Ÿ - {date_str}"

        content = '\n'.join(lines[content_start:]) if content_start > 0 else ai_response

        tags = self._extract_tags(content)

        return {
            'title': f"åŒºå—é“¾æ¯æ—¥è§‚å¯Ÿ - {date_str}",
            'content': content,
            'description': description[:200],  # é™åˆ¶200å­—ç¬¦
            'tags': tags
        }

    def _extract_tags(self, content: str) -> List[str]:
        """Extract tags from content"""
        tags = ['åŒºå—é“¾', 'æ¯æ—¥è§‚å¯Ÿ']

        content_lower = content.lower()

        if 'defi' in content_lower or 'å»ä¸­å¿ƒåŒ–é‡‘è' in content:
            tags.append('DeFi')
        if 'nft' in content_lower or 'æ•°å­—è—å“' in content:
            tags.append('NFT')
        if 'æ¯”ç‰¹å¸' in content or 'bitcoin' in content_lower or 'btc' in content_lower:
            tags.append('æ¯”ç‰¹å¸')
        if 'ä»¥å¤ªåŠ' in content or 'ethereum' in content_lower or 'eth' in content_lower:
            tags.append('ä»¥å¤ªåŠ')
        if 'ç›‘ç®¡' in content or 'æ”¿ç­–' in content:
            tags.append('æ”¿ç­–ç›‘ç®¡')
        if 'èèµ„' in content or 'æŠ•èµ„' in content:
            tags.append('æŠ•èèµ„')

        return list(set(tags))

    def _generate_attractive_title_and_cover(self, news_text: str, article_content: str) -> Dict[str, str]:
        """
        Generate attractive title and cover image prompt based on article content

        Args:
            news_text: Raw news text
            article_content: Processed article content

        Returns:
            Dict with 'title' and 'cover_prompt'
        """
        try:
            prompt = f"""åŸºäºä»¥ä¸‹åŒºå—é“¾æ–°é—»æ–‡ç« ï¼Œç”Ÿæˆä¸€ä¸ªå¸å¼•äººçš„YouTubeè§†é¢‘æ ‡é¢˜å’Œå°é¢å›¾æè¿°ã€‚

æ–‡ç« æ‘˜è¦:
{article_content[:1000]}...

è¦æ±‚:

1. **YouTubeè§†é¢‘æ ‡é¢˜**ï¼ˆ10-25ä¸ªå­—ï¼‰:
   - æŠ“ä½ä»Šæ—¥æœ€æ ¸å¿ƒã€æœ€å¸å¼•çœ¼çƒçš„è¯é¢˜
   - ä½¿ç”¨æ•°å­—ã€æƒ…æ„Ÿè¯ã€æ‚¬å¿µç­‰æŠ€å·§
   - é€‚åˆYouTubeç®—æ³•æ¨è
   - ç¤ºä¾‹: "æ¯”ç‰¹å¸æš´è·Œ20%ï¼å·¨é²¸å´åœ¨ç–¯ç‹‚æŠ„åº•ï¼Ÿ"
   - ç¤ºä¾‹: "ä»¥å¤ªåŠé‡å¤§å‡çº§ï¼Gasè´¹ç”¨é™ä½90%"
   - ç¤ºä¾‹: "ç¾å›½SECçªå‘æ–°æ”¿ï¼åŠ å¯†å¸‚åœºå°†è¿æ¥å·¨å˜ï¼Ÿ"

2. **å°é¢å›¾æç¤ºè¯**ï¼ˆè‹±æ–‡ï¼Œç”¨äºNano Banana Proå›¾ç‰‡ç”Ÿæˆï¼‰:
   - å¿…é¡»åŒ…å«å¸å¼•äººçš„äººç‰©åœºæ™¯
   - çªå‡ºä»Šæ—¥æœ€é‡è¦çš„ä¸»é¢˜
   - é€‚åˆYouTubeç¼©ç•¥å›¾ï¼ˆ16:9æ¨ªå±ï¼‰
   - åŒ…å«æ¸…æ™°çš„ä¸­æ–‡æ ‡é¢˜æ–‡å­—
   - è§†è§‰å†²å‡»åŠ›å¼ºï¼Œè®©äººæƒ³ç‚¹å‡»
   - ç¬¦åˆNano Banana Proçš„æ–‡å­—æ¸²æŸ“ä¼˜åŠ¿

è¯·ä»¥JSONæ ¼å¼è¿”å›:
{{
  "title": "å¸å¼•äººçš„YouTubeæ ‡é¢˜",
  "cover_prompt": "Detailed English prompt for cover image generation"
}}

å°é¢å›¾æç¤ºè¯ç¤ºä¾‹æ ¼å¼:
"Create a dramatic YouTube thumbnail image for blockchain news.
Scene: Shocked/excited business analyst looking at large digital screen showing [KEY EVENT],
dramatic lighting, urgent atmosphere, close-up professional photography style.
Chinese title text: '[YouTubeæ ‡é¢˜]' in large bold white characters (90pt+) at top,
highly visible and readable using Nano Banana Pro's superior text rendering.
Visual elements: Bitcoin/crypto symbols, price charts with dramatic arrows,
breaking news aesthetic, red/green color accents for market emotions.
Background: Gradient dark blue to black, cinematic lighting, high contrast.
Style: YouTube thumbnail optimized, attention-grabbing, professional yet dramatic,
perfect for video presentation, 16:9 horizontal format.
Text rendering: Ensure Chinese characters are crystal clear and prominent using
Nano Banana Pro's industry-leading multilingual text capabilities."

æ³¨æ„: æ ‡é¢˜è¦èƒ½å¼•èµ·å¥½å¥‡å¿ƒå’Œç‚¹å‡»æ¬²æœ›ï¼Œå°é¢å›¾è¦è§†è§‰å†²å‡»åŠ›å¼ºï¼"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.8,  # ç¨é«˜çš„æ¸©åº¦ä»¥è·å¾—æ›´æœ‰åˆ›æ„çš„æ ‡é¢˜
                max_tokens=2000
            )

            result = response.choices[0].message.content

            # Parse JSON response
            import json
            import re

            # Extract JSON from markdown code blocks if present
            json_match = re.search(r'```json\s*(.*?)\s*```', result, re.DOTALL)
            if json_match:
                result = json_match.group(1)

            parsed = json.loads(result)

            self.logger.info(f"Generated attractive title: {parsed['title']}")
            return parsed

        except Exception as e:
            self.logger.error(f"Error generating attractive title and cover: {e}")
            # Fallback
            return {
                'title': 'ä»Šæ—¥åŒºå—é“¾è¡Œä¸šé‡å¤§åŠ¨æ€',
                'cover_prompt': 'Professional blockchain news presenter looking at dramatic market charts, urgent atmosphere, Chinese title text visible'
            }

    def _basic_format(self, news_list: List[Dict[str, Any]], date_str: str) -> Dict[str, Any]:
        """Basic formatting without AI"""
        content_parts = [
            f"# åŒºå—é“¾æ¯æ—¥è§‚å¯Ÿ - {date_str}\n",
            f"ä»Šæ—¥å…±æ”¶å½• {len(news_list)} æ¡åŒºå—é“¾è¡Œä¸šåŠ¨æ€\n",
            "---\n"
        ]

        # Group by source
        sources = {}
        for news in news_list:
            source = news.get('source', 'å…¶ä»–')
            if source not in sources:
                sources[source] = []
            sources[source].append(news)

        for source, source_news in sources.items():
            content_parts.append(f"\n## ğŸ“° {source}\n")
            for news in source_news:
                content_parts.append(f"- **{news['title']}**  \n  {news['content']}\n")

        content = '\n'.join(content_parts)

        return {
            'title': f"åŒºå—é“¾æ¯æ—¥è§‚å¯Ÿ - {date_str}",
            'content': content,
            'description': f"åŒºå—é“¾æ¯æ—¥è§‚å¯Ÿ - {date_str},æ”¶å½•{len(news_list)}æ¡è¡Œä¸šåŠ¨æ€",
            'tags': ['åŒºå—é“¾', 'æ¯æ—¥è§‚å¯Ÿ'],
            'attractive_title': f'ä»Šæ—¥åŒºå—é“¾è¡Œä¸šåŠ¨æ€ - {date_str}',
            'cover_prompt': 'Professional blockchain news, modern office setting'
        }
