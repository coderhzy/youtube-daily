"""
AI Processor for news content using OpenRouter
"""

from typing import List, Dict, Any
from openai import OpenAI

from src.config import (
    OPENROUTER_API_KEY,
    OPENROUTER_BASE_URL,
    OPENROUTER_MODEL,
    ENABLE_AI_SUMMARY
)
from src.utils.logger import get_logger

class AIProcessor:
    """AI processor using OpenRouter for content generation"""

    def __init__(self):
        self.logger = get_logger('ai_processor')

        if not OPENROUTER_API_KEY:
            raise ValueError("OPENROUTER_API_KEY must be set in environment variables")

        self.client = OpenAI(
            api_key=OPENROUTER_API_KEY,
            base_url=OPENROUTER_BASE_URL
        )
        self.model = OPENROUTER_MODEL
        self.logger.info(f"AI Processor initialized with model: {self.model}")

    def process_daily_news(
        self,
        news_list: List[Dict[str, Any]],
        date_str: str
    ) -> Dict[str, Any]:
        """
        Process daily news and generate blog article

        Args:
            news_list: List of news items
            date_str: Date string (YYYY-MM-DD)

        Returns:
            Dict containing title, content, description, tags
        """
        if not ENABLE_AI_SUMMARY:
            self.logger.info("AI summary is disabled, using basic formatting")
            return self._basic_format(news_list, date_str)

        try:
            self.logger.info(f"Processing {len(news_list)} news items with AI...")

            # Prepare news text
            news_text = self._prepare_news_text(news_list)

            # Call AI to generate article
            prompt = self._create_prompt(news_text, date_str)

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„åŒºå—é“¾è¡Œä¸šåˆ†æå¸ˆå’Œæ·±åº¦å†…å®¹åˆ›ä½œè€…,æ“…é•¿æ’°å†™è¯¦å®ã€æœ‰æ´å¯ŸåŠ›çš„è¡Œä¸šè§‚å¯Ÿæ–‡ç« ã€‚ä½ çš„æ–‡ç« ä¿¡æ¯é‡å¤§ã€åˆ†ææ·±å…¥,æ·±å—ä¸“ä¸šè¯»è€…å–œçˆ±ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=16000  # æ”¯æŒæ›´é•¿çš„è¾“å‡ºï¼ˆçº¦10kä¸­æ–‡å­—ï¼‰
            )

            result = response.choices[0].message.content

            # Parse AI response
            parsed_result = self._parse_ai_response(result, date_str)

            self.logger.info("AI processing completed successfully")
            return parsed_result

        except Exception as e:
            self.logger.error(f"Error in AI processing: {e}")
            self.logger.info("Falling back to basic formatting")
            return self._basic_format(news_list, date_str)

    def _prepare_news_text(self, news_list: List[Dict[str, Any]]) -> str:
        """Prepare news text for AI processing"""
        news_items = []
        for i, news in enumerate(news_list, 1):
            source = news.get('source', 'æœªçŸ¥æ¥æº')
            title = news.get('title', '')
            content = news.get('content', '')

            news_items.append(
                f"{i}. [{source}] {title}\n   {content}"
            )

        return "\n\n".join(news_items)

    def _create_prompt(self, news_text: str, date_str: str) -> str:
        """Create AI prompt"""
        return f"""è¯·å°†ä»¥ä¸‹åŒºå—é“¾æ–°é—»æ•´ç†æˆä¸€ç¯‡**æ·±åº¦ã€è¯¦ç»†**çš„æ¯æ—¥è§‚å¯Ÿåšå®¢æ–‡ç« ã€‚

æ—¥æœŸ: {date_str}

æ–°é—»å†…å®¹:
{news_text}

è¯·æŒ‰ä»¥ä¸‹è¦æ±‚å¤„ç†:

1. **æ–‡ç« é•¿åº¦**: ç›®æ ‡8000-10000å­—ï¼Œéœ€è¦è¯¦ç»†å±•å¼€æ¯æ¡æ–°é—»çš„èƒŒæ™¯ã€å½±å“å’Œåˆ†æ

2. **æ–‡ç« ç»“æ„**:

   a) **å¼€ç¯‡æ€»ç»“** (500-800å­—):
      - ç”¨3-5æ®µè¯æ€»ç»“ä»Šæ—¥æœ€é‡è¦çš„åŠ¨æ€
      - æç‚¼æ ¸å¿ƒä¸»é¢˜å’Œè¶‹åŠ¿
      - è®¾ç½®é˜…è¯»æœŸå¾…

   b) **åˆ†ç±»æ·±åº¦æŠ¥é“**: å°†æ–°é—»åˆ†ä¸ºä»¥ä¸‹æ¿å—ï¼Œæ¯ä¸ªæ¿å—è¯¦ç»†å±•å¼€:
      - ğŸ“Š **å¸‚åœºåŠ¨æ€** (ä»·æ ¼ã€äº¤æ˜“é‡ã€å¸‚åœºæƒ…ç»ªã€æŠ€æœ¯åˆ†æ)
      - ğŸ›ï¸ **æ”¿ç­–ç›‘ç®¡** (å„å›½ç›‘ç®¡åŠ¨å‘ã€åˆè§„è¦æ±‚ã€æ”¿ç­–å½±å“)
      - ğŸ’° **DeFiç”Ÿæ€** (åè®®æ›´æ–°ã€TVLå˜åŒ–ã€æ”¶ç›Šæœºä¼šã€é£é™©åˆ†æ)
      - ğŸ¨ **NFTä¸é“¾æ¸¸** (æ–°é¡¹ç›®ã€äº¤æ˜“æ•°æ®ã€å¸‚åœºçƒ­ç‚¹)
      - ğŸ”§ **æŠ€æœ¯åˆ›æ–°** (åè®®å‡çº§ã€Layer2è¿›å±•ã€æ–°æŠ€æœ¯è½åœ°)
      - ğŸ’¼ **æŠ•èèµ„** (èèµ„äº‹ä»¶ã€æŠ•èµ„æœºæ„åŠ¨å‘ã€ä¼°å€¼åˆ†æ)
      - ğŸŒ **è¡Œä¸šåŠ¨æ€** (æœºæ„å…¥åœºã€ç”Ÿæ€å‘å±•ã€è¡Œä¸šåˆä½œ)

   c) **æ·±åº¦åˆ†æ** (1000-1500å­—):
      - ä»Šæ—¥æ–°é—»çš„å…³è”æ€§åˆ†æ
      - å¯¹è¡Œä¸šè¶‹åŠ¿çš„å½±å“
      - æ½œåœ¨æœºä¼šå’Œé£é™©æç¤º

3. **å†…å®¹æ·±åº¦è¦æ±‚**:
   - **æ¯æ¡é‡è¦æ–°é—»**: ç”¨150-300å­—å±•å¼€ï¼ŒåŒ…æ‹¬:
     * äº‹ä»¶èƒŒæ™¯ä»‹ç»
     * è¯¦ç»†æ•°æ®å’Œäº‹å®
     * ä¸šå†…è§‚ç‚¹å¼•ç”¨
     * æ½œåœ¨å½±å“åˆ†æ

   - **æ¬¡è¦æ–°é—»**: ç”¨80-150å­—æ¦‚æ‹¬

   - **æ·»åŠ ä¸“ä¸šæ´å¯Ÿ**:
     * å¼•ç”¨è¡Œä¸šæ•°æ®å’ŒæŒ‡æ ‡
     * å¯¹æ¯”å†å²äº‹ä»¶
     * åˆ†æå› æœå…³ç³»
     * é¢„æµ‹æœªæ¥èµ°å‘

4. **è¯­è¨€é£æ ¼**:
   - ä¸“ä¸šä½†æ˜“æ‡‚ï¼Œé¢å‘å¯¹åŒºå—é“¾æœ‰ä¸€å®šäº†è§£çš„è¯»è€…
   - ä½¿ç”¨æ•°æ®æ”¯æ’‘è§‚ç‚¹
   - ä¿æŒå®¢è§‚ä¸­ç«‹ï¼Œä½†å¯ä»¥æä¾›ç‹¬åˆ°è§è§£
   - é€‚å½“ä½¿ç”¨è¡Œä¸šæœ¯è¯­ï¼Œå¹¶ç®€è¦è§£é‡Š

5. **æ ¼å¼è¦æ±‚**:
   - ä½¿ç”¨Markdownæ ¼å¼
   - æ¯ä¸ªæ¿å—ç”¨äºŒçº§æ ‡é¢˜(##)
   - é‡è¦æ–°é—»ç”¨ä¸‰çº§æ ‡é¢˜(###)
   - æ¬¡è¦æ–°é—»ç”¨åˆ—è¡¨é¡¹(-)
   - å…³é”®æ•°æ®ç”¨**ç²—ä½“**æ ‡æ³¨
   - é€‚å½“ä½¿ç”¨å¼•ç”¨å—(>)çªå‡ºé‡è¦è§‚ç‚¹

è¯·ç›´æ¥è¾“å‡ºMarkdownæ ¼å¼çš„æ–‡ç« å†…å®¹ï¼Œç¡®ä¿å†…å®¹å……å®ã€åˆ†ææ·±å…¥ã€ä¿¡æ¯é‡å¤§ã€‚"""

    def _parse_ai_response(self, ai_response: str, date_str: str) -> Dict[str, Any]:
        """Parse AI response"""
        lines = ai_response.strip().split('\n')
        description_lines = []
        content_start = 0

        for i, line in enumerate(lines):
            if line.startswith('##'):
                content_start = i
                break
            if line.strip() and not line.startswith('#'):
                description_lines.append(line.strip())

        description = ' '.join(description_lines[:3]) if description_lines else f"åŒºå—é“¾æ¯æ—¥è§‚å¯Ÿ - {date_str}"

        content = '\n'.join(lines[content_start:]) if content_start > 0 else ai_response

        tags = self._extract_tags(content)

        return {
            'title': f"åŒºå—é“¾æ¯æ—¥è§‚å¯Ÿ - {date_str}",
            'content': content,
            'description': description[:200],
            'tags': tags
        }

    def _extract_tags(self, content: str) -> List[str]:
        """Extract tags from content"""
        tags = ['åŒºå—é“¾', 'æ¯æ—¥è§‚å¯Ÿ']

        content_lower = content.lower()

        if 'defi' in content_lower or 'å»ä¸­å¿ƒåŒ–é‡‘è' in content:
            tags.append('DeFi')
        if 'nft' in content_lower or 'æ•°å­—è—å“' in content:
            tags.append('NFT')
        if 'æ¯”ç‰¹å¸' in content or 'bitcoin' in content_lower or 'btc' in content_lower:
            tags.append('æ¯”ç‰¹å¸')
        if 'ä»¥å¤ªåŠ' in content or 'ethereum' in content_lower or 'eth' in content_lower:
            tags.append('ä»¥å¤ªåŠ')
        if 'ç›‘ç®¡' in content or 'æ”¿ç­–' in content:
            tags.append('æ”¿ç­–ç›‘ç®¡')
        if 'èèµ„' in content or 'æŠ•èµ„' in content:
            tags.append('æŠ•èèµ„')

        return list(set(tags))

    def _basic_format(self, news_list: List[Dict[str, Any]], date_str: str) -> Dict[str, Any]:
        """Basic formatting without AI"""
        content_parts = [
            f"# åŒºå—é“¾æ¯æ—¥è§‚å¯Ÿ - {date_str}\n",
            f"ä»Šæ—¥å…±æ”¶å½• {len(news_list)} æ¡åŒºå—é“¾è¡Œä¸šåŠ¨æ€\n",
            "---\n"
        ]

        # Group by source
        sources = {}
        for news in news_list:
            source = news.get('source', 'å…¶ä»–')
            if source not in sources:
                sources[source] = []
            sources[source].append(news)

        for source, source_news in sources.items():
            content_parts.append(f"\n## ğŸ“° {source}\n")
            for news in source_news:
                content_parts.append(f"- **{news['title']}**  \n  {news['content']}\n")

        content = '\n'.join(content_parts)

        return {
            'title': f"åŒºå—é“¾æ¯æ—¥è§‚å¯Ÿ - {date_str}",
            'content': content,
            'description': f"åŒºå—é“¾æ¯æ—¥è§‚å¯Ÿ - {date_str},æ”¶å½•{len(news_list)}æ¡è¡Œä¸šåŠ¨æ€",
            'tags': ['åŒºå—é“¾', 'æ¯æ—¥è§‚å¯Ÿ']
        }
